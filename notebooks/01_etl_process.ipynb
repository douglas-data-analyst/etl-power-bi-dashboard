{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL - Extração, Transformação e Carga de Dados de E-commerce\n",
    "\n",
    "Este notebook implementa um pipeline completo de ETL (Extração, Transformação e Carga) para dados de e-commerce da Olist, preparando-os para visualização no Power BI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Importações\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "# Ignorando avisos para melhor visualização\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Adicionando diretório src ao path para importar módulos personalizados\n",
    "sys.path.append('../src')\n",
    "import etl_functions as etl\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Configurações de visualização\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('viridis')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extração de Dados\n",
    "\n",
    "Nesta seção, extraímos dados de diferentes fontes. Em um cenário real, isso poderia incluir bancos de dados, APIs, arquivos CSV, Excel, etc. Para este exemplo, usaremos dados de e-commerce da Olist disponíveis no Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Definindo função para criar dados de exemplo se os arquivos não existirem\n",
    "def create_sample_data():\n",
    "    \"\"\"Cria dados de exemplo para demonstração do ETL\"\"\"\n",
    "    print(\"Criando dados de exemplo para demonstração...\")\n",
    "    \n",
    "    # Criando diretório se não existir\n",
    "    os.makedirs('../data/raw', exist_ok=True)\n",
    "    \n",
    "    # Dados de exemplo - Clientes\n",
    "    customers_data = {\n",
    "        'customer_id': [f'cust_{i}' for i in range(1, 101)],\n",
    "        'customer_unique_id': [f'uniq_{i}' for i in range(1, 101)],\n",
    "        'customer_zip_code_prefix': np.random.randint(10000, 99999, 100),\n",
    "        'customer_city': np.random.choice(['São Paulo', 'Rio de Janeiro', 'Belo Horizonte', 'Porto Alegre', 'Brasília'], 100),\n",
    "        'customer_state': np.random.choice(['SP', 'RJ', 'MG', 'RS', 'DF'], 100)\n",
    "    }\n",
    "    pd.DataFrame(customers_data).to_csv('../data/raw/olist_customers_dataset.csv', index=False)\n",
    "    \n",
    "    # Dados de exemplo - Pedidos\n",
    "    orders_data = {\n",
    "        'order_id': [f'order_{i}' for i in range(1, 201)],\n",
    "        'customer_id': np.random.choice([f'cust_{i}' for i in range(1, 101)], 200),\n",
    "        'order_status': np.random.choice(['delivered', 'shipped', 'processing', 'canceled'], 200, p=[0.7, 0.1, 0.1, 0.1]),\n",
    "        'order_purchase_timestamp': pd.date_range(start='2022-01-01', end='2022-12-31', periods=200).astype(str),\n",
    "        'order_approved_at': pd.date_range(start='2022-01-01', end='2022-12-31', periods=200).astype(str),\n",
    "        'order_delivered_carrier_date': pd.date_range(start='2022-01-02', end='2023-01-01', periods=200).astype(str),\n",
    "        'order_delivered_customer_date': pd.date_range(start='2022-01-05', end='2023-01-05', periods=200).astype(str),\n",
    "        'order_estimated_delivery_date': pd.date_range(start='2022-01-10', end='2023-01-10', periods=200).astype(str)\n",
    "    }\n",
    "    pd.DataFrame(orders_data).to_csv('../data/raw/olist_orders_dataset.csv', index=False)\n",
    "    \n",
    "    # Dados de exemplo - Produtos\n",
    "    products_data = {\n",
    "        'product_id': [f'prod_{i}' for i in range(1, 151)],\n",
    "        'product_category_name': np.random.choice(['electronics', 'furniture', 'toys', 'books', 'clothing'], 150),\n",
    "        'product_name_length': np.random.randint(10, 100, 150),\n",
    "        'product_description_length': np.random.randint(100, 1000, 150),\n",
    "        'product_photos_qty': np.random.randint(1, 10, 150),\n",
    "        'product_weight_g': np.random.randint(100, 10000, 150),\n",
    "        'product_length_cm': np.random.randint(10, 100, 150),\n",
    "        'product_height_cm': np.random.randint(5, 50, 150),\n",
    "        'product_width_cm': np.random.randint(5, 50, 150)\n",
    "    }\n",
    "    pd.DataFrame(products_data).to_csv('../data/raw/olist_products_dataset.csv', index=False)\n",
    "    \n",
    "    # Dados de exemplo - Itens de Pedido\n",
    "    order_items_data = {\n",
    "        'order_id': np.random.choice([f'order_{i}' for i in range(1, 201)], 300),\n",
    "        'order_item_id': np.random.randint(1, 5, 300),\n",
    "        'product_id': np.random.choice([f'prod_{i}' for i in range(1, 151)], 300),\n",
    "        'seller_id': np.random.choice([f'seller_{i}' for i in range(1, 51)], 300),\n",
    "        'shipping_limit_date': pd.date_range(start='2022-01-01', end='2022-12-31', periods=300).astype(str),\n",
    "        'price': np.random.uniform(10, 1000, 300).round(2),\n",
    "        'freight_value': np.random.uniform(5, 100, 300).round(2)\n",
    "    }\n",
    "    pd.DataFrame(order_items_data).to_csv('../data/raw/olist_order_items_dataset.csv', index=False)\n",
    "    \n",
    "    # Dados de exemplo - Vendedores\n",
    "    sellers_data = {\n",
    "        'seller_id': [f'seller_{i}' for i in range(1, 51)],\n",
    "        'seller_zip_code_prefix': np.random.randint(10000, 99999, 50),\n",
    "        'seller_city': np.random.choice(['São Paulo', 'Rio de Janeiro', 'Belo Horizonte', 'Curitiba', 'Salvador'], 50),\n",
    "        'seller_state': np.random.choice(['SP', 'RJ', 'MG', 'PR', 'BA'], 50)\n",
    "    }\n",
    "    pd.DataFrame(sellers_data).to_csv('../data/raw/olist_sellers_dataset.csv', index=False)\n",
    "    \n",
    "    # Dados de exemplo - Avaliações\n",
    "    reviews_data = {\n",
    "        'review_id': [f'review_{i}' for i in range(1, 201)],\n",
    "        'order_id': [f'order_{i}' for i in range(1, 201)],\n",
    "        'review_score': np.random.randint(1, 6, 200),\n",
    "        'review_comment_title': [f'Title {i}' if i % 3 == 0 else None for i in range(1, 201)],\n",
    "        'review_comment_message': [f'Message {i}' if i % 2 == 0 else None for i in range(1, 201)],\n",
    "        'review_creation_date': pd.date_range(start='2022-01-01', end='2022-12-31', periods=200).astype(str),\n",
    "        'review_answer_timestamp': pd.date_range(start='2022-01-02', end='2023-01-01', periods=200).astype(str)\n",
    "    }\n",
    "    pd.DataFrame(reviews_data).to_csv('../data/raw/olist_order_reviews_dataset.csv', index=False)\n",
    "    \n",
    "    # Dados de exemplo - Categorias em Português/Inglês\n",
    "    category_translation_data = {\n",
    "        'product_category_name': ['electronics', 'furniture', 'toys', 'books', 'clothing'],\n",
    "        'product_category_name_english': ['electronics', 'furniture', 'toys', 'books', 'clothing']\n",
    "    }\n",
    "    pd.DataFrame(category_translation_data).to_csv('../data/raw/product_category_name_translation.csv', index=False)\n",
    "    \n",
    "    print(\"Dados de exemplo criados com sucesso!\")\n",
    "\n",
    "# Verificando se os arquivos existem, caso contrário, criando dados de exemplo\n",
    "required_files = [\n",
    "    '../data/raw/olist_customers_dataset.csv',\n",
    "    '../data/raw/olist_orders_dataset.csv',\n",
    "    '../data/raw/olist_products_dataset.csv',\n",
    "    '../data/raw/olist_order_items_dataset.csv',\n",
    "    '../data/raw/olist_sellers_dataset.csv',\n",
    "    '../data/raw/olist_order_reviews_dataset.csv',\n",
    "    '../data/raw/product_category_name_translation.csv'\n",
    "]\n",
    "\n",
    "if not all(os.path.exists(file) for file in required_files):\n",
    "    create_sample_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Extraindo dados dos arquivos CSV\n",
    "print(\"Extraindo dados...\")\n",
    "\n",
    "# Usando a função de extração do módulo etl_functions\n",
    "raw_data = etl.extract_data('../data/raw/')\n",
    "\n",
    "# Verificando os dataframes extraídos\n",
    "for name, df in raw_data.items():\n",
    "    print(f\"{name}: {df.shape[0]} linhas, {df.shape[1]} colunas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transformação de Dados\n",
    "\n",
    "Nesta seção, realizamos várias transformações nos dados brutos para prepará-los para análise e visualização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Convertendo colunas de data para datetime\n",
    "print(\"Transformando dados...\")\n",
    "\n",
    "# Usando a função de transformação do módulo etl_functions\n",
    "transformed_data = etl.transform_data(raw_data)\n",
    "\n",
    "# Verificando os dataframes transformados\n",
    "for name, df in transformed_data.items():\n",
    "    print(f\"{name}: {df.shape[0]} linhas, {df.shape[1]} colunas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Criando tabelas dimensionais e fato para modelo estrela\n",
    "print(\"Criando modelo dimensional...\")\n",
    "\n",
    "# Usando a função de criação de modelo dimensional do módulo etl_functions\n",
    "dim_tables, fact_table = etl.create_dimensional_model(transformed_data)\n",
    "\n",
    "# Verificando as tabelas dimensionais\n",
    "print(\"\\nTabelas Dimensionais:\")\n",
    "for name, df in dim_tables.items():\n",
    "    print(f\"{name}: {df.shape[0]} linhas, {df.shape[1]} colunas\")\n",
    "\n",
    "# Verificando a tabela fato\n",
    "print(f\"\\nTabela Fato: {fact_table.shape[0]} linhas, {fact_table.shape[1]} colunas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando Exemplos das Tabelas Dimensionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualizando exemplos das tabelas dimensionais\n",
    "for name, df in dim_tables.items():\n",
    "    print(f\"\\n{name} (primeiras 5 linhas):\")\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando Exemplo da Tabela Fato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualizando exemplo da tabela fato\n",
    "print(\"\\nTabela Fato (primeiras 5 linhas):\")\n",
    "display(fact_table.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Criação de Tabelas Agregadas para Análise\n",
    "\n",
    "Nesta seção, criamos tabelas agregadas que serão úteis para visualizações e dashboards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Criando tabelas agregadas para análise\n",
    "print(\"Criando tabelas agregadas...\")\n",
    "\n",
    "# Usando a função de criação de tabelas agregadas do módulo etl_functions\n",
    "agg_tables = etl.create_aggregated_tables(fact_table, dim_tables)\n",
    "\n",
    "# Verificando as tabelas agregadas\n",
    "for name, df in agg_tables.items():\n",
    "    print(f\"{name}: {df.shape[0]} linhas, {df.shape[1]} colunas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando Exemplos das Tabelas Agregadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualizando exemplos das tabelas agregadas\n",
    "for name, df in agg_tables.items():\n",
    "    print(f\"\\n{name} (primeiras 5 linhas):\")\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Carga de Dados\n",
    "\n",
    "Nesta seção, salvamos os dados transformados e agregados em formatos adequados para uso no Power BI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Salvando dados transformados\n",
    "print(\"Salvando dados transformados...\")\n",
    "\n",
    "# Criando diretório para dados transformados se não existir\n",
    "os.makedirs('../data/transformed', exist_ok=True)\n",
    "\n",
    "# Salvando tabelas dimensionais\n",
    "for name, df in dim_tables.items():\n",
    "    df.to_csv(f'../data/transformed/dim_{name}.csv', index=False)\n",
    "    print(f\"Tabela dimensional '{name}' salva com sucesso.\")\n",
    "\n",
    "# Salvando tabela fato\n",
    "fact_table.to_csv('../data/transformed/fact_sales.csv', index=False)\n",
    "print(\"Tabela fato 'sales' salva com sucesso.\")\n",
    "\n",
    "# Salvando tabelas agregadas\n",
    "for name, df in agg_tables.items():\n",
    "    df.to_csv(f'../data/transformed/agg_{name}.csv', index=False)\n",
    "    print(f\"Tabela agregada '{name}' salva com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Salvando dados em formato parquet para melhor desempenho no Power BI\n",
    "print(\"\\nSalvando dados em formato parquet...\")\n",
    "\n",
    "# Salvando tabelas dimensionais em parquet\n",
    "for name, df in dim_tables.items():\n",
    "    df.to_parquet(f'../data/transformed/dim_{name}.parquet')\n",
    "    print(f\"Tabela dimensional '{name}' salva em parquet com sucesso.\")\n",
    "\n",
    "# Salvando tabela fato em parquet\n",
    "fact_table.to_parquet('../data/transformed/fact_sales.parquet')\n",
    "print(\"Tabela fato 'sales' salva em parquet com sucesso.\")\n",
    "\n",
    "# Salvando tabelas agregadas em parquet\n",
    "for name, df in agg_tables.items():\n",
    "    df.to_parquet(f'../data/transformed/agg_{name}.parquet')\n",
    "    print(f\"Tabela agregada '{name}' salva em parquet com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verificação dos Dados Transformados\n",
    "\n",
    "Nesta seção, realizamos algumas verificações para garantir que os dados foram transformados corretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Verificando integridade dos dados\n",
    "print(\"Verificando integridade dos dados...\")\n",
    "\n",
    "# Verificando se todas as chaves estrangeiras na tabela fato existem nas tabelas dimensionais\n",
    "for dim_name, dim_df in dim_tables.items():\n",
    "    if f'{dim_name}_id' in fact_table.columns:\n",
    "        fk_values = fact_table[f'{dim_name}_id'].unique()\n",
    "        pk_values = dim_df['id'].unique()\n",
    "        missing_keys = set(fk_values) - set(pk_values)\n",
    "        if missing_keys:\n",
    "            print(f\"ERRO: Chaves estrangeiras ausentes na dimensão {dim_name}: {missing_keys}\")\n",
    "        else:\n",
    "            print(f\"OK: Todas as chaves estrangeiras para a dimensão {dim_name} estão presentes.\")\n",
    "\n",
    "# Verificando valores nulos em colunas importantes\n",
    "print(\"\\nVerificando valores nulos em colunas importantes da tabela fato:\")\n",
    "null_counts = fact_table[['order_id', 'customer_id', 'product_id', 'seller_id', 'date_id', 'price', 'freight_value']].isnull().sum()\n",
    "print(null_counts)\n",
    "\n",
    "# Verificando consistência dos dados agregados\n",
    "print(\"\\nVerificando consistência dos dados agregados:\")\n",
    "total_sales_fact = fact_table['price'].sum()\n",
    "total_sales_agg = agg_tables['sales_by_date']['total_sales'].sum()\n",
    "print(f\"Total de vendas na tabela fato: {total_sales_fact:.2f}\")\n",
    "print(f\"Total de vendas na tabela agregada por data: {total_sales_agg:.2f}\")\n",
    "print(f\"Diferença: {abs(total_sales_fact - total_sales_agg):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualização Prévia para o Dashboard\n",
    "\n",
    "Nesta seção, criamos algumas visualizações preliminares que servirão de base para o dashboard no Power BI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Criando visualizações preliminares\n",
    "print(\"Criando visualizações preliminares...\")\n",
    "\n",
    "# Criando diretório para figuras se não existir\n",
    "os.makedirs('../reports/dashboard', exist_ok=True)\n",
    "\n",
    "# Vendas por mês\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='month', y='total_sales', data=agg_tables['sales_by_date'], palette='viridis')\n",
    "plt.title('Vendas Totais por Mês', fontsize=16)\n",
    "plt.xlabel('Mês', fontsize=12)\n",
    "plt.ylabel('Vendas Totais (R$)', fontsize=12)\n",
    "plt.xticks(range(12), ['Jan', 'Fev', 'Mar', 'Abr', 'Mai', 'Jun', 'Jul', 'Ago', 'Set', 'Out', 'Nov', 'Dez'])\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('../reports/dashboard/sales_by_month.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Vendas por categoria\n",
    "plt.figure(figsize=(14, 8))\n",
    "category_sales = agg_tables['sales_by_category'].sort_values('total_sales', ascending=False).head(10)\n",
    "sns.barplot(y='category_name', x='total_sales', data=category_sales, palette='viridis')\n",
    "plt.title('Top 10 Categorias por Vendas', fontsize=16)\n",
    "plt.xlabel('Vendas Totais (R$)', fontsize=12)\n",
    "plt.ylabel('Categoria', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('../reports/dashboard/sales_by_category.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Vendas por estado\n",
    "plt.figure(figsize=(14, 8))\n",
    "state_sales = agg_tables['sales_by_location'].sort_values('total_sales', ascending=False).head(10)\n",
    "sns.barplot(y='state', x='total_sales', data=state_sales, palette='viridis')\n",
    "plt.title('Top 10 Estados por Vendas', fontsize=16)\n",
    "plt.xlabel('Vendas Totais (R$)', fontsize=12)\n",
    "plt.ylabel('Estado', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('../reports/dashboard/sales_by_state.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Distribuição de avaliações\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='review_score', data=dim_tables['review'], palette='viridis')\n",
    "plt.title('Distribuição de Avaliações', fontsize=16)\n",
    "plt.xlabel('Pontuação da Avaliação', fontsize=12)\n",
    "plt.ylabel('Número de Avaliações', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('../reports/dashboard/review_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Criação de Imagem de Exemplo do Dashboard\n",
    "\n",
    "Nesta seção, criamos uma imagem de exemplo do dashboard que será incluída no README do projeto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Criando uma imagem de exemplo do dashboard\n",
    "print(\"Criando imagem de exemplo do dashboard...\")\n",
    "\n",
    "# Criando um layout de dashboard simples com as visualizações criadas\n",
    "fig, axes = plt.subplots(2, 2, figsize=(20, 15))\n",
    "\n",
    "# Vendas por mês\n",
    "sns.barplot(x='month', y='total_sales', data=agg_tables['sales_by_date'], palette='viridis', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Vendas Totais por Mês', fontsize=16)\n",
    "axes[0, 0].set_xlabel('Mês', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Vendas Totais (R$)', fontsize=12)\n",
    "axes[0, 0].set_xticks(range(12))\n",
    "axes[0, 0].set_xticklabels(['Jan', 'Fev', 'Mar', 'Abr', 'Mai', 'Jun', 'Jul', 'Ago', 'Set', 'Out', 'Nov', 'Dez'])\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Vendas por categoria\n",
    "category_sales = agg_tables['sales_by_category'].sort_values('total_sales', ascending=False).head(10)\n",
    "sns.barplot(y='category_name', x='total_sales', data=category_sales, palette='viridis', ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Top 10 Categorias por Vendas', fontsize=16)\n",
    "axes[0, 1].set_xlabel('Vendas Totais (R$)', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Categoria', fontsize=12)\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Vendas por estado\n",
    "state_sales = agg_tables['sales_by_location'].sort_values('total_sales', ascending=False).head(10)\n",
    "sns.barplot(y='state', x='total_sales', data=state_sales, palette='viridis', ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Top 10 Estados por Vendas', fontsize=16)\n",
    "axes[1, 0].set_xlabel('Vendas Totais (R$)', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Estado', fontsize=12)\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Distribuição de avaliações\n",
    "sns.countplot(x='review_score', data=dim_tables['review'], palette='viridis', ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Distribuição de Avaliações', fontsize=16)\n",
    "axes[1, 1].set_xlabel('Pontuação da Avaliação', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Número de Avaliações', fontsize=12)\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Adicionando título geral\n",
    "fig.suptitle('Dashboard de Vendas E-commerce', fontsize=24, y=0.98)\n",
    "\n",
    "# Ajustando layout\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "\n",
    "# Salvando imagem do dashboard\n",
    "plt.savefig('../reports/dashboard/dashboard_preview.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Instruções para Integração com Power BI\n",
    "\n",
    "Nesta seção, fornecemos instruções para integrar os dados transformados com o Power BI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passos para Integração com Power BI\n",
    "\n",
    "1. **Abra o Power BI Desktop**\n",
    "\n",
    "2. **Importe os dados transformados**:\n",
    "   - Clique em \"Obter Dados\" > \"Arquivo\" > \"Pasta\"\n",
    "   - Navegue até a pasta `data/transformed`\n",
    "   - Selecione os arquivos .parquet (recomendado) ou .csv\n",
    "\n",
    "3. **Configure as relações entre tabelas**:\n",
    "   - Vá para a visualização \"Modelo\"\n",
    "   - Crie relações entre a tabela fato e as tabelas dimensionais usando as chaves correspondentes:\n",
    "     - fact_sales.customer_id → dim_customer.id\n",
    "     - fact_sales.product_id → dim_product.id\n",
    "     - fact_sales.seller_id → dim_seller.id\n",
    "     - fact_sales.date_id → dim_date.id\n",
    "     - fact_sales.order_id → dim_order.id\n",
    "\n",
    "4. **Crie medidas calculadas**:\n",
    "   - Clique com o botão direito na tabela fact_sales > \"Nova medida\"\n",
    "   - Crie medidas como:\n",
    "     ```\n",
    "     Total Vendas = SUM(fact_sales[price])\n",
    "     Total Frete = SUM(fact_sales[freight_value])\n",
    "     Ticket Médio = DIVIDE(SUM(fact_sales[price]), DISTINCTCOUNT(fact_sales[order_id]))\n",
    "     ```\n",
    "\n",
    "5. **Crie visualizações**:\n",
    "   - Gráfico de barras para vendas por categoria\n",
    "   - Gráfico de linhas para tendência de vendas ao longo do tempo\n",
    "   - Mapa para vendas por estado\n",
    "   - Cartões para KPIs como total de vendas, número de pedidos, ticket médio\n",
    "   - Gráfico de pizza para distribuição de avaliações\n",
    "\n",
    "6. **Adicione segmentações de dados**:\n",
    "   - Adicione segmentações por período, categoria, estado, etc.\n",
    "\n",
    "7. **Formate o dashboard**:\n",
    "   - Organize as visualizações\n",
    "   - Adicione título e descrições\n",
    "   - Aplique um tema consistente\n",
    "\n",
    "8. **Salve o arquivo .pbix**:\n",
    "   - Salve na pasta `reports/dashboard`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Conclusão\n",
    "\n",
    "Neste notebook, implementamos um pipeline completo de ETL para dados de e-commerce, incluindo:\n",
    "\n",
    "1. **Extração** de dados de múltiplas fontes\n",
    "2. **Transformação** dos dados brutos em um modelo dimensional (estrela)\n",
    "3. **Criação** de tabelas agregadas para análise\n",
    "4. **Carga** dos dados transformados em formatos adequados para o Power BI\n",
    "5. **Verificação** da integridade dos dados\n",
    "6. **Visualização** preliminar para o dashboard\n",
    "7. **Instruções** para integração com Power BI\n",
    "\n",
    "Os dados estão prontos para serem importados no Power BI para criar um dashboard interativo e completo de análise de vendas de e-commerce."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
